{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff4a0d4-fb18-46dc-8a3b-c96871ccab96",
   "metadata": {},
   "source": [
    "# Double-q learning\n",
    "An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3868c1a9-005a-4c3a-8c67-4de29236b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46309347-1c60-4e6e-8c2e-bc5229689850",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56acddc7-8467-4f46-95eb-e9901f3cbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_states = {\n",
    "    \"A\": 0,\n",
    "    \"B\": 1,\n",
    "}\n",
    "\n",
    "map_actions = {\n",
    "    \"left\": 0,\n",
    "    \"right\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e8a96c-ff70-4bf2-aa6c-b776134342cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms_B = 10\n",
    "rewards = np.random.normal(loc=-1, scale=1, size=n_arms_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e76ecd87-c46c-45f3-8cd4-5860a4a6e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def step(state, action):\n",
    "    if state == 0:\n",
    "        reward = 0\n",
    "        if action == 1: #Â right\n",
    "            new_state = 0\n",
    "        if action == 0: # left\n",
    "            new_state = 1\n",
    "\n",
    "    if state == 1:\n",
    "        new_state = 0\n",
    "        reward = rewards[action]\n",
    "\n",
    "    return new_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b82e32-a573-49c2-a116-470fefc327f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qv = (\n",
    "    np.zeros(2,),\n",
    "    np.zeros(n_arms_B,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1aff883-0e39-48e7-9618-09333d02a9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 0.1\n",
    "state = 1\n",
    "agents.choose_action(state, Qv, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3086e0f-b1eb-414d-9f08-256edd2fe6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_step(state, Q, epsilon):\n",
    "    action = agents.choose_action(state, Q)\n",
    "    new_state, reward = step(state, action)\n",
    "    q_new = Q[state][action] + alpha * (reward + gamma * Q[state].max() - Q[state][action])\n",
    "    return q_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numbaenv",
   "language": "python",
   "name": "numbaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
