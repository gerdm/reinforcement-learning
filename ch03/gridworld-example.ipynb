{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d627048",
   "metadata": {},
   "source": [
    "# Gridworld Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95c330",
   "metadata": {},
   "source": [
    "Rules:\n",
    "1. If you are at $A$, you get a reward of +10 irrespective of the action only if you land in $A'$\n",
    "2. If you are at $B$, you get a reward of +5 irrespective of the action only if you land in $B'$\n",
    "3. If you are at a boundary except for $A$ and $B$, you get -1 if you take an action that takes you out of bounds, but you remain in the same state\n",
    "4. Any other step has zero reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7662dc-2591-45e8-9bcb-d69ec55eeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adc905-bf71-4dcf-bd34-e504c26b0e5e",
   "metadata": {},
   "source": [
    "## Suboptimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1df97-79f0-4539-a568-e2c9bf03f2f4",
   "metadata": {},
   "source": [
    "To solve the gridworld example, we suppose that the agent selects all four actions with equal probabilty in all states ( $\\forall a.\\pi(a\\vert s) = \\frac{1}{4}$). By the Jacobi-Bellman equation, we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    v_\\pi(s) &= \\sum_{a} \\pi(a\\vert s) \\sum_{s',r} p(s', r \\vert s, a)[r + \\gamma v_\\pi(s')]\\\\\n",
    "             &= \\frac{1}{4}\\sum_{a, s', r} p(s', r \\vert s, a) [r + \\gamma v_\\pi(s')]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence, every state $s$ needs to satisfy\n",
    "\n",
    "$$\n",
    "    \\sum_{s'}v_\\pi(s') \\left[\\mathbb{1}(s' = s) - \\frac{\\gamma}{4}\\sum_{a}p(s' \\vert s, a)\\right] = \\frac{1}{4} \\sum_{a,s',r} r \\cdot p(s',r\\vert s,a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb2e60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4, 4, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actions, rewards, (*state)\n",
    "n_actions = 4\n",
    "n_rewards = 4\n",
    "state_size = 25\n",
    "\n",
    "# p(s',r | a, s)\n",
    "p_gridworld = np.zeros((state_size, n_rewards, n_actions, state_size))\n",
    "p_gridworld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0ca54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 0\n",
    "upper_bound = np.sqrt(state_size).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39abbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([0, 5, 10, -1])\n",
    "reward_map = {r: ix for ix, r in enumerate(rewards)}\n",
    "\n",
    "actions = [\"up\", \"right\", \"down\", \"left\"]\n",
    "actions_ix_map = {a: ix for ix, a in enumerate(actions)}\n",
    "\n",
    "action_map = {\n",
    "    \"up\": np.array([-1, 0]),\n",
    "    \"right\": np.array([0, 1]),\n",
    "    \"down\": np.array([1, 0]),\n",
    "    \"left\": np.array([0, -1])\n",
    "}\n",
    "\n",
    "# mapping from special states to rewards\n",
    "special_map = {\n",
    "    1: 10,\n",
    "    3: 5\n",
    "}\n",
    "\n",
    "# mapping from special states to terminal states\n",
    "special_states = [1, 3]\n",
    "special_state_map = {\n",
    "    1: 21,\n",
    "    3: 13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cc4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(ix):\n",
    "    col = ix % 5\n",
    "    row = ix // 5\n",
    "    state = np.asarray([row, col])\n",
    "    return state\n",
    "\n",
    "def get_state(position):\n",
    "    row, col = position\n",
    "    return 5 * row + col\n",
    "\n",
    "def move(state, action):\n",
    "    position = get_pos(state)\n",
    "    new_position = position + action_map[action]\n",
    "    return new_position\n",
    "\n",
    "def is_out_of_bounds(position, lb=0, ub=4):\n",
    "    return (new_pos < lb).any() or (new_pos > ub).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5ba295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=10, action=up   , [0 1] -> [4 1]\n",
      "r=10, action=right, [0 1] -> [4 1]\n",
      "r=10, action=down , [0 1] -> [4 1]\n",
      "r=10, action=left , [0 1] -> [4 1]\n"
     ]
    }
   ],
   "source": [
    "# p(s',r | a, s)\n",
    "p_gridworld = np.zeros((state_size, n_rewards, n_actions, state_size))\n",
    "for s in range(state_size):\n",
    "    curr_pos = get_pos(s)\n",
    "    for r in reward_map:\n",
    "        for action in action_map:\n",
    "            a_pos = actions_ix_map[action]\n",
    "            r_pos = reward_map[r]\n",
    "            new_pos = move(s, action)\n",
    "            new_state = get_state(new_pos)\n",
    "\n",
    "            val = 0\n",
    "            if s in special_states:\n",
    "                if r == special_map[s]:\n",
    "                    val = 1\n",
    "                new_state = special_state_map[s]\n",
    "                new_pos = get_pos(new_state)\n",
    "            elif is_out_of_bounds(new_pos):\n",
    "                if r == -1:\n",
    "                    val = 1\n",
    "                new_pos = curr_pos\n",
    "                new_state = s\n",
    "            elif r == 0:\n",
    "                val = 1\n",
    "            \n",
    "            if val == 1 and r == 10:\n",
    "                pass\n",
    "                print(f\"{r=:2}, {action=:5}, {curr_pos} -> {new_pos}\")\n",
    "            p_gridworld[new_state, r_pos, a_pos, s] = val\n",
    "p_gridworld = p_gridworld / p_gridworld.sum(axis=0, keepdims=True).sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8587a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Σ_{s', r, a} r * p(s', r | a, s)\n",
    "b = (p_gridworld * rewards[None, :, None, None]).sum(axis=0).sum(axis=0).sum(axis=0) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf2ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 0.9\n",
    "I = np.eye(state_size)\n",
    "A = I - γ / 4 * p_gridworld.sum(axis=1).sum(axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60122edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3,  8.8,  4.4,  5.3,  1.5],\n",
       "       [ 1.5,  3. ,  2.3,  1.9,  0.5],\n",
       "       [ 0.1,  0.7,  0.7,  0.4, -0.4],\n",
       "       [-1. , -0.4, -0.4, -0.6, -1.2],\n",
       "       [-1.9, -1.3, -1.2, -1.4, -2. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(A, b).reshape(5, 5).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9528c-c15f-4cf3-8c51-a313d88b1e58",
   "metadata": {},
   "source": [
    "## Optimal Policy\n",
    "\n",
    "$$\n",
    "    v_{*}(s) = \\max_{a\\in\\mathcal{A}} \\sum_{s',r}p\\left( s', r \\vert s, a \\right)\\left[r + \\gamma v_*(s')\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c7ce85-1fb6-4ba0-aa34-185723b52a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_optimality(vs):\n",
    "    rhs = (rewards[None, :] + γ * vs[:, None])[..., None, None] * p_gridworld\n",
    "    rhs = rhs.sum(axis=0).sum(axis=0).max(axis=0)\n",
    "    \n",
    "    return vs - rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f733da-e0d0-425d-83fd-f7f871efb1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22. , 24.4, 22. , 19.4, 17.5],\n",
       "       [19.8, 22. , 19.8, 17.8, 16. ],\n",
       "       [17.8, 19.8, 17.8, 16. , 14.4],\n",
       "       [16. , 17.8, 16. , 14.4, 13. ],\n",
       "       [14.4, 16. , 14.4, 13. , 11.7]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = np.random.randn(25)\n",
    "vs_star = optimize.broyden1(bellman_optimality, vs)\n",
    "vs_star.reshape(5, 5).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635863d-8886-401e-864e-79ea7afca4f3",
   "metadata": {},
   "source": [
    "### Optimal actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f98d193-1b29-489b-837e-f14f670800a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dec = 3\n",
    "optimal_actions = (rewards[None, :] + γ * vs_star[:, None])[..., None, None] * p_gridworld\n",
    "optimal_actions = optimal_actions.sum(axis=0).sum(axis=0).round(n_dec) == vs_star[None, :].round(n_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a304f056-930b-4610-b232-1af4c9d5d8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['r   ', 'urdl', 'l   ', 'urdl', 'l   '],\n",
       "       ['ur  ', 'u   ', 'ul  ', 'l   ', 'l   '],\n",
       "       ['ur  ', 'u   ', 'ul  ', 'ul  ', 'ul  '],\n",
       "       ['ur  ', 'u   ', 'ul  ', 'ul  ', 'ul  '],\n",
       "       ['ur  ', 'u   ', 'ul  ', 'ul  ', 'ul  ']], dtype='<U4')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Up, right, left, down actions\n",
    "actions_str = np.where(optimal_actions, np.array([\"u\",\"r\",\"d\",\"l\"])[:, None], \"\").T\n",
    "np.array([f'{\"\".join(row):4}' for row in actions_str]).reshape(5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probml",
   "language": "python",
   "name": "probml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
