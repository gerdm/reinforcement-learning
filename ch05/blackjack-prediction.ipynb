{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab394903-07c2-4325-9189-80070f0f3350",
   "metadata": {},
   "source": [
    "# Blackjack - prediction\n",
    "\n",
    "In this notebook, we are interested in *learning* the value-function $v_\\pi(s)$ and action-value function $q_\\pi(s, a)$ for a given policy $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd929d34-5f36-4754-b653-f0f2171e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debf50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71627d2e",
   "metadata": {},
   "source": [
    "* **Stick**: Player stops\n",
    "* **Hit**: Request an additional card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cbb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.core import types\n",
    "from numba.typed import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d77a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def draw_card():\n",
    "    return np.random.multinomial(1, deck_probs).argmax()\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def dealer_strategy(value_cards):\n",
    "    \"\"\"\n",
    "    Dealer's fixed strategy\n",
    "    \"\"\"\n",
    "    while value_cards < 17:\n",
    "        value_cards = value_cards + draw_card()\n",
    "    return value_cards\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def update_player_card(current_value, new_card):\n",
    "    \"\"\"\n",
    "    Update the player's hand value.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_value: int\n",
    "        Current value of player's hand\n",
    "    new_card: int\n",
    "        Randomly-drawn card\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (int, bool)\n",
    "        1. New value of player's hand\n",
    "        2. Whether the there is a usable ace.\n",
    "    \"\"\"\n",
    "    has_usable_ace = False\n",
    "    if new_card == 1.0 and current_value <= 10:\n",
    "        new_card = 11\n",
    "        has_usable_ace = True\n",
    "        \n",
    "    new_value = current_value + new_card\n",
    "    return new_value, has_usable_ace\n",
    "\n",
    "@jit(nopython=True)\n",
    "def blackjack(player_value_cards, dealer_cards, policy, has_usable_ace):\n",
    "    \"\"\"\n",
    "    Evaluate a single play of Blackjack.\n",
    "    \n",
    "    For some reason, a player can only have a minimum value of 12\n",
    "    on her initial value cards.\n",
    "    \n",
    "    At the start of the game, we are given the initial value of the cards\n",
    "    of the player, the initial dealer cards and a policy for the player.\n",
    "    Furtheremore, we are given whether the player has a usable ace.\n",
    "    \n",
    "    Actions:\n",
    "        0: hit\n",
    "        1: stick\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    player_value_cards: float\n",
    "        Current value cards for the players\n",
    "    dealer_cards: jnp.array(2)\n",
    "        Dealer's initial cards\n",
    "    policy: jnp.array(G,A)\n",
    "        2d-array specifying if having value g ∈ G the player\n",
    "        should take action a ∈ A, i.e., policy[g,a] == 1.0\n",
    "        if action a should be taken if the value of the cards\n",
    "        is g.\n",
    "    has_usable_ace: bool\n",
    "        Wehether the initial player_value_cards contains a\n",
    "        usable ace.\n",
    "    \"\"\"\n",
    "    reward = 0\n",
    "    \n",
    "    hist_reward = [reward]\n",
    "    hist_state = [(player_value_cards, has_usable_ace)]\n",
    "    hist_action = [0]\n",
    "    \n",
    "    \n",
    "    dealer_value_cards = np.sum(dealer_cards)\n",
    "    \n",
    "    # Stick if you have 21\n",
    "    if player_value_cards == 21 and dealer_value_cards != 21:\n",
    "        reward = 1\n",
    "        \n",
    "        hist_reward.append(reward)\n",
    "        hist_state.append((player_value_cards, has_usable_ace))\n",
    "        hist_action.append(1)\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    # Strickly speaking, the policy should depend on:\n",
    "    #  1. The current state of the player, i.e., the value of her cards\n",
    "    #  2. The only card we observe of the dealer\n",
    "    # In this example, we consider a policy that only depends\n",
    "    # on the current value of the player's cards.\n",
    "\n",
    "    # Hit until you reach a 'stick' state or you lose (value of cards over 21)\n",
    "    while policy[player_value_cards - 12][1] != 1.0:\n",
    "        new_card = draw_card()\n",
    "        player_value_cards, new_has_usable_ace = update_player_card(player_value_cards, new_card)\n",
    "        has_usable_ace = has_usable_ace or new_has_usable_ace # keep usable ace if player already did have one.\n",
    "        hist_reward.append(0)\n",
    "        hist_action.append(0)\n",
    "        hist_state.append((player_value_cards, has_usable_ace))\n",
    "        \n",
    "        if player_value_cards > 21:\n",
    "            break\n",
    "            \n",
    "    dealer_value_cards = dealer_strategy(sum(dealer_cards))\n",
    "    \n",
    "    if player_value_cards > 21:\n",
    "        reward = -1\n",
    "    elif dealer_value_cards > 21:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = 1 if player_value_cards > dealer_value_cards else 0\n",
    "    \n",
    "    hist_reward.append(reward)\n",
    "    \n",
    "    return reward, hist_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd9d67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We consider the policy that sticks if the \n",
    "# player's sum is 20 or 21, and otherwise hits\n",
    "policy = np.zeros((10, 2))\n",
    "policy[:-2, 0] = 1\n",
    "policy[-2:, 1] = 1\n",
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49dfa5a-29b2-4302-880b-0d1ac660bd8b",
   "metadata": {},
   "source": [
    "## A Jax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff28ddc-4118-4055-ba52-e290c448bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerardoduran/miniforge3/envs/rl/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e0de9571-b584-4049-b8ed-315b41b30868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider an initial policy that sticks if the\n",
    "# player's sum is 20 or 21 and otherwise hits\n",
    "# Sp | A | Cd\n",
    "policy = jnp.zeros((10, 2, 10))\n",
    "policy = (policy.at[:-2, 0, :].set(1) # Sum less than 20 => hits\n",
    "                .at[-2:, 1, :].set(1)) # Sum == 20 or 21 => stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "674e539b-21be-4f9f-9d92-90263cc119f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(1., dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of player's hand (Sp) | dealer's shown card (Cd) | whether player has usable card (A)\n",
    "state_0 = jnp.array([20, 1, 2])\n",
    "\n",
    "hand_sum, dealer_card, has_ace = state_0\n",
    "policy[hand_sum, dealer_card, has_ace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f760e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value 10 corresponds to 10, Jack, Queen, and King.\n",
    "# n_vals = jnp.ones(10).at[-1].set(4)\n",
    "# deck_probs = n_vals / n_vals.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d46ba247-ceaa-4cd0-a42f-d7b75efabafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 cards valued 1 through 9; 10, Jack, Queen and King are worth 10\n",
    "\n",
    "def draw_cards(key, n=1):\n",
    "    n_vals = jnp.ones(10).at[-1].set(4)\n",
    "    deck_probs = n_vals / n_vals.sum()\n",
    "    cards = jax.random.choice(key, 10, (n,), p=deck_probs)\n",
    "    return cards\n",
    "    \n",
    "\n",
    "def init_player_state(key):\n",
    "    \"\"\"\n",
    "    Random initialisiation of player's card. At the beginning we draw two cards.\n",
    "    If the sum of the cards is less than 12, we continue hitting until we reach\n",
    "    at least 12.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    key: jax.random.PRNGKey\n",
    "        Initial player's key\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple(\n",
    "        1. initial value of cards\n",
    "        2. whether there was a usable ace\n",
    "    )\n",
    "    \"\"\"\n",
    "    init_cards = draw_cards(key, 2) + 1\n",
    "\n",
    "    value_cards = init_cards.sum()\n",
    "    usable_ace = (init_cards[0] == 1) + (init_cards[1] == 1)\n",
    "    value_cards = init_cards.sum() + 10 * usable_ace\n",
    "    \n",
    "    with loops.Scope() as s:\n",
    "        s.value = value_cards\n",
    "        s.usable_ace = usable_ace\n",
    "        _, new_key = jax.random.split(key)\n",
    "        for _ in s.while_range(lambda: s.value < 12):\n",
    "            new_card = jnp.squeeze(draw_cards(new_key))\n",
    "            new_card, usable_ace = jax.lax.cond((s.value <= 10) * (new_card == 1), lambda: (11, True), lambda: (1, False))\n",
    "            s.usable_ace = s.usable_ace | usable_ace\n",
    "            s.value = s.value + new_card\n",
    "            _, new_key = jax.random.split(new_key)\n",
    "    \n",
    "    value_cards = s.value\n",
    "    usable_ace = s.usable_ace\n",
    "    \n",
    "    return init_cards, value_cards, usable_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "547ae42d-d984-4e2c-abdd-3f39d91cffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_game(key):\n",
    "    \"\"\"\n",
    "    Create initial game of blackjack.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    key: jax.random.PRNGkey\n",
    "        Initial key\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    * array: sum of players hand, whether player holds usable ace, dealers' only showing card\n",
    "    * int: initial value of dealers's hand\n",
    "    \"\"\"\n",
    "    key_player, key_dealer = jax.random.split(key)\n",
    "    _, *player_state = init_player_state(key_player)\n",
    "    dealer_cards, value_dealer, _ = init_player_state(key_dealer)\n",
    "    \n",
    "    dealer_card = dealer_cards[0] # Dealer's one-showing card\n",
    "    \n",
    "    return jnp.asarray([*player_state, dealer_card]), value_dealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "25c8c4c0-dbf5-430a-ad41-4a2804913948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[12,  0,  1],\n",
       "              [18,  0,  3],\n",
       "              [14,  0,  3],\n",
       "              [20,  0,  1],\n",
       "              [18,  0, 10],\n",
       "              [12,  0,  9],\n",
       "              [12,  0,  3],\n",
       "              [13,  0,  3],\n",
       "              [21,  1,  4],\n",
       "              [17,  0,  5],\n",
       "              [12,  0, 10],\n",
       "              [17,  0,  9],\n",
       "              [12,  0, 10],\n",
       "              [20,  0,  4],\n",
       "              [12,  0,  4],\n",
       "              [20,  0,  7],\n",
       "              [12,  0,  3],\n",
       "              [14,  0,  5],\n",
       "              [12,  0,  2],\n",
       "              [16,  0,  2]], dtype=int32),\n",
       " DeviceArray([17, 14, 13, 16, 15, 19, 13, 12, 12, 12, 20, 13, 18, 20, 12,\n",
       "              18, 12, 14, 12, 12], dtype=int32))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(3141)\n",
    "\n",
    "n_simulations = 20\n",
    "keys = jax.random.split(key, n_simulations)\n",
    "\n",
    "jax.vmap(init_game)(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "06caa195-4e37-4ab2-97bc-10c343d8792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackjack_step(state, policy):\n",
    "    \"\"\"\n",
    "    Compute a single step of blackjack.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    state: jnp.array(3)\n",
    "        * Player's current sum\n",
    "        * Dealer's one-showing card\n",
    "        * Whether player has usable ace\n",
    "    policy: jnp.array(N,K,M)\n",
    "        Policy grid specifying whether to \"hit\" or \"stick\"\n",
    "        N: Card value 12,...,21\n",
    "        K: Action values 1,2\n",
    "        M: Dealer's one-hand 1,...,10\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        * Array of next state\n",
    "        * Reward at the end of the step\n",
    "        * whether the game has reached an end-state.\n",
    "    \"\"\"\n",
    "    # Possible conditions\n",
    "    # * Check if hand is natural\n",
    "    # 1. Player plays according to his policy\n",
    "    # 2. Dealer plays according to his policy\n",
    "    state, d_value, reward, terminal = jax.lax.cond(\n",
    "        is_draw(state, d_value),\n",
    "        true_fun=lambda _: update_draw(...),\n",
    "        false_fun=jax.lax.cond(\n",
    "            player_wins(state, d_value),\n",
    "            true_fun=lambda _: state\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf9800-42fc-4387-b7f8-cf17483b2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dealer = jnp.zeros(10).at[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e0fc71fb-3000-472e-b052-03cd788b190c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0., dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_0 = jnp.array([7, 1, 2])\n",
    "\n",
    "policy[tuple(state_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ae5e01c9-81c7-42a6-8e98-2fbfc5000d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 10)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e1999-12af-4972-9f6f-33fb6e0b5a27",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://github.com/ShangtongZhang/reinforcement-learning-an-introduction/blob/master/chapter05/blackjack.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement-learning",
   "language": "python",
   "name": "reinforcement-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
