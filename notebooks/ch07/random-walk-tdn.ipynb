{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c878419a-29c6-4a5c-8e82-086ec470251a",
   "metadata": {},
   "source": [
    "# $n$-step TD on a random walk\n",
    "\n",
    "We consider a modified random Markov process (MRP) presented in example 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318a5bde-bf4b-4298-8c4e-5278939a4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "from tqdm import tqdm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a4f2a8-4dd4-4d0c-b06c-5ec4f8431a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb4fca5-7573-40df-84a3-8fef6d2a720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33bba695-2be7-4ed9-9a33-e3f9b336d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c045b08-51c9-45f0-bce8-8a66aeb88d03",
   "metadata": {},
   "source": [
    "The state-value update using TD-1 is\n",
    "$$\n",
    "V(S_t) \\gets V(S_t) + \\alpha\\left[R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)\\right].\n",
    "$$\n",
    "\n",
    "The state-value update using TD-2 is\n",
    "$$\n",
    "V(S_t) \\gets V(S_t) + \\alpha\\left[ R_{t+1} + \\gamma R_{t+2} + \\gamma^2 V(S_{t+2}) - V(S_t) \\right].\n",
    "$$\n",
    "\n",
    "For any $n>2$, the state-value update of TD-$n$ is\n",
    "$$\n",
    "V(S_t) \\gets V(S_t) + \\alpha\\left[\\sum_{k=1}^n \\gamma^{k-1} R_{t+k} + \\gamma^n V(S_{t+n}) - V(S_t) \\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7e131-9d5f-4dfe-bc23-03983afd2f4d",
   "metadata": {},
   "source": [
    "**Note**: for an episode with $T$ timesteps, if $n \\geq T$, then TD reduces to an MC update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59c0405-cc86-4cf0-a221-66f13ecb8943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0.5],\n",
       "       [0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states = 19 + 1 # total state plus terminal state\n",
    "states = np.arange(n_states)\n",
    "mrp = np.zeros((n_states, n_states))\n",
    "mrp[0, 0] = 1.0\n",
    "\n",
    "for i in range(1, n_states):\n",
    "    iprev = i - 1\n",
    "    inext = (i + 1) % n_states\n",
    "    mrp[i, [i - 1, inext]] = 1/2\n",
    "\n",
    "mrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc4046d-b4c4-451c-be04-814b1bff24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_states -1\n",
    "reward_matrix = np.eye(n)\n",
    "reward_matrix = reward_matrix - np.eye(n, k=1) / 2 - np.eye(n, k=-1) / 2\n",
    "y = np.zeros(n)\n",
    "y[-1] = 1/2\n",
    "y[0] = -1/2\n",
    "\n",
    "value_array = np.linalg.solve(reward_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb0b8bf-9ccc-44d6-b19b-8de06a26ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "@njit\n",
    "def sample_run(s):\n",
    "    s_hist = [s]\n",
    "    r_hist = []\n",
    "    r = 0\n",
    "    while s != 0:\n",
    "        snext = np.random.multinomial(1, mrp[s]).argmax()\n",
    "        r = 1 if (s == n_states - 1) and (snext == 0) else 0\n",
    "        s = snext\n",
    "        s_hist.append(s)\n",
    "        r_hist.append(r)\n",
    "    \n",
    "    s_hist = np.array(s_hist[:-1])\n",
    "    r_hist = np.array(r_hist)\n",
    "    return s_hist, r_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdcb3e-3eee-4ac0-aebd-c3fd703a3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2718)\n",
    "\n",
    "n_sims = 10\n",
    "\n",
    "for n in range(n_sims):\n",
    "    s_hist, r_hist = sample_run(5)\n",
    "    len_hist = len(s_hist)\n",
    "    plt.plot(s_hist)\n",
    "    plt.scatter(len_hist, s_hist[-1], s=50)\n",
    "\n",
    "plt.grid(alpha=0.3)\n",
    "plt.axhline(y=n_states - 1, c=\"black\")\n",
    "plt.axhline(y=1, c=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f88961-3025-4458-aef0-0dc9994d3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def compute_reward(sprev, snext):\n",
    "    if (sprev == n_states - 1) and (snext == 0):\n",
    "        r = 1\n",
    "    elif (sprev == 1) and (snext == 0):\n",
    "        r = -1\n",
    "    else:\n",
    "        r = 0\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "@njit\n",
    "def run_and_update_tdn(value, s, alpha, gamma, td_size):\n",
    "    \"\"\"\n",
    "    Sample from the MRP and update the TD-n algorithm\n",
    "    ----\n",
    "    Parameters:\n",
    "    value: np.array\n",
    "        Current value estimate\n",
    "    s: float\n",
    "        initial state\n",
    "    alpha: float\n",
    "        learning rate\n",
    "    gamma: float\n",
    "        discount\n",
    "    rewards_td: np.array\n",
    "        FIFO buffer of rewards\n",
    "    \"\"\"\n",
    "    value = value.copy()\n",
    "    \n",
    "    rewards_td = np.zeros(td_size) * np.nan # rewards in the buffer\n",
    "    states_td = -np.ones(td_size, dtype=np.int32) # states S_{t+n} to update\n",
    "    discount_array = gamma ** np.arange(td_size)\n",
    "\n",
    "    # Run simulation and fill buffer\n",
    "    while s != 0:\n",
    "        # 1. take action\n",
    "        snext = np.random.multinomial(1, mrp[s]).argmax()\n",
    "        \n",
    "        # 2. observe reward and store\n",
    "        r = compute_reward(s, snext)\n",
    "        \n",
    "        rewards_td = np.roll(rewards_td, -1)\n",
    "        rewards_td[-1] = r\n",
    "        \n",
    "        states_td = np.roll(states_td, -1)\n",
    "        states_td[-1] = snext\n",
    "        \n",
    "        \n",
    "        # If the buffer is not filled, we haven't reached the pair S_t -> S_{t+n}.\n",
    "        if np.any(np.isnan(rewards_td)):\n",
    "            s = snext\n",
    "            continue\n",
    "\n",
    "        s_back = states_td[0]\n",
    "        target = (discount_array * rewards_td).sum() + gamma ** td_size * value[s_back]\n",
    "        value[s] = value[s] + alpha * (target - value[s])\n",
    "        \n",
    "        s = snext\n",
    "\n",
    "    # Exhaust elements in buffer\n",
    "    for i, s in enumerate(states_td, 1):\n",
    "        if (s == -1) or (s == 0): # terminal or non-valid state\n",
    "            continue\n",
    "\n",
    "        subset = rewards_td[i:]\n",
    "        lsubset = len(subset)\n",
    "        discounts = gamma ** np.arange(lsubset)\n",
    "        G = (discounts * subset).sum()\n",
    "        value[s] = value[s] + alpha * (G - value[s])\n",
    "\n",
    "    # value[np.isnan(rewards_td)] = np.nan\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def tdn_value_sims(\n",
    "        value_init, sinit, alpha, gamma, td_size, n_sims, n_episodes\n",
    "    ):\n",
    "    value_all = np.zeros((n_sims, len(value_init)))\n",
    "    for n in prange(n_sims):\n",
    "        value = value_init.copy()\n",
    "        for e in range(n_episodes):\n",
    "            value = run_and_update_tdn(value, sinit, alpha, gamma, td_size)\n",
    "        value_all[n] = value\n",
    "    return value_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502be83-6fd4-40e0-a6f7-d398f8c86f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_init = np.zeros(n_states)\n",
    "\n",
    "gamma  = 1.0\n",
    "sinit = 9\n",
    "\n",
    "n_episodes = 200\n",
    "n_sims = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e9667-3163-4e36-ae83-62bb1085a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values =[2 ** n for n in range(10)]\n",
    "alpha_values = np.linspace(0, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec9d02-8c75-4fe9-b61f-b7b41c988f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(product(n_values, alpha_values))\n",
    "\n",
    "collection = []\n",
    "for td_size, a in tqdm(items):\n",
    "    value = tdn_value_sims(value_init, sinit, a, gamma, td_size, n_sims, n_episodes)\n",
    "    err = np.nanmean(np.sqrt(np.nanmean(np.power(value[:, 1:] - value_array[None, :], 2), axis=-1)))\n",
    "    collection.append({\n",
    "        \"n\": td_size,\n",
    "        \"alpha\": a,\n",
    "        \"rmse\": err,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd8319-d9a4-46ea-9f11-b9938200e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e6efa-96e8-4302-8294-a7ffa5154a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_values:\n",
    "    res.query(\"n == @n\").query(\"rmse < 0.6\").set_index(\"alpha\")[\"rmse\"].plot()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.ylabel(\"RMSE\", fontsize=15)\n",
    "plt.xlabel(r\"$\\alpha$\", fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numbaenv",
   "language": "python",
   "name": "numbaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
