{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce627da-6dc0-4319-a7bb-4018d6b103ae",
   "metadata": {},
   "source": [
    "# Gridworld Example\n",
    "\n",
    "Rules:\n",
    "1. If you are at $A$, you get a reward of +10 irrespective of the action only if you land in $A'$\n",
    "2. If you are at $B$, you get a reward of +5 irrespective of the action only if you land in $B'$\n",
    "3. If you are at a boundary except for $A$ and $B$, you get -1 if you take an action that takes you out of bounds, but you remain in the same state\n",
    "4. Any other step has zero reward\n",
    "\n",
    "\n",
    "## The Bellman equation\n",
    "$$\n",
    "    v_\\pi(s) = \\sum_{a} \\pi(a | s)\\sum_{s', r} p(s', r | a, s) [r + \\gamma v_\\pi(s')]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7662dc-2591-45e8-9bcb-d69ec55eeef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import einops\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adc905-bf71-4dcf-bd34-e504c26b0e5e",
   "metadata": {},
   "source": [
    "## Suboptimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1df97-79f0-4539-a568-e2c9bf03f2f4",
   "metadata": {},
   "source": [
    "To solve the gridworld example, we suppose that the agent selects all four actions with equal probabilty in all states ( $\\forall a.\\pi(a\\vert s) = \\frac{1}{4}$). By the Bellman equation, we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    v_\\pi(s) &= \\sum_{a} \\pi(a\\vert s) \\sum_{s',r} p(s', r \\vert s, a)[r + \\gamma v_\\pi(s')]\\\\\n",
    "             &= \\frac{1}{4}\\sum_{a, s', r} p(s', r \\vert s, a) [r + \\gamma v_\\pi(s')]\n",
    "\\end{aligned}\n",
    "$$\n",
    "Equation $(1)$ above can be rewritten as\n",
    "$$\n",
    "    \\sum_{s'}v_\\pi(s') \\left[\\mathbb{1}(s' = s) - \\frac{\\gamma}{4}\\sum_{a,r}p(s', r \\vert s, a)\\right] =\n",
    "    \\frac{1}{4} \\sum_{a,s',r} r \\cdot p(s',r\\vert s,a)\n",
    "$$\n",
    "\n",
    "Let ${\\bf v}_\\pi \\in \\mathbb{R}^{\\cal S}$,\n",
    "$$\n",
    "    A_{s',s} = \\mathbb{1}(s' = s) - \\frac{\\gamma}{4}\\sum_{a,r}p(s', r \\vert s, a),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "    {\\bf b}_{s} = \\frac{1}{4} \\sum_{a,s',r} r \\cdot p(s',r\\vert s,a)\n",
    "$$\n",
    "\n",
    "we have\n",
    "$$\n",
    "    {\\bf A}{\\bf v}_\\pi = {\\bf b}.\n",
    "$$\n",
    "\n",
    "Hence, by building ${\\bf A}$ and $\\bf b$, ${\\bf v}_\\pi$ is estimated solving the system of equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb2e60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# actions, rewards, (*state)\n",
    "n_actions = 4\n",
    "n_rewards = 4\n",
    "state_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0ca54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lower_bound = 0\n",
    "upper_bound = np.sqrt(state_size).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39abbf75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rewards = np.array([0, 5, 10, -1])\n",
    "reward_map = {r: ix for ix, r in enumerate(rewards)}\n",
    "\n",
    "actions = [\"up\", \"right\", \"down\", \"left\"]\n",
    "actions_ix_map = {a: ix for ix, a in enumerate(actions)}\n",
    "\n",
    "action_map = {\n",
    "    \"up\": np.array([-1, 0]),\n",
    "    \"right\": np.array([0, 1]),\n",
    "    \"down\": np.array([1, 0]),\n",
    "    \"left\": np.array([0, -1])\n",
    "}\n",
    "\n",
    "# mapping from special states to rewards\n",
    "special_map = {\n",
    "    1: 10,\n",
    "    3: 5\n",
    "}\n",
    "\n",
    "# mapping from special states to terminal states\n",
    "special_states = [1, 3]\n",
    "special_state_map = {\n",
    "    1: 21,\n",
    "    3: 13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cc4e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pos(ix):\n",
    "    \"\"\"\n",
    "    From state to coordinate position\n",
    "    \"\"\"\n",
    "    col = ix % 5\n",
    "    row = ix // 5\n",
    "    state = np.asarray([row, col])\n",
    "    return state\n",
    "\n",
    "\n",
    "def get_state(position):\n",
    "    \"\"\"\n",
    "    From coordinate position to state\n",
    "    \"\"\"\n",
    "    row, col = position\n",
    "    return 5 * row + col\n",
    "\n",
    "\n",
    "def is_out_of_bounds(position, lb=0, ub=4):\n",
    "    \"\"\"\n",
    "    Check if coordinate position is out of bounds\n",
    "    \"\"\"\n",
    "    return (position < lb).any() or (position > ub).any()\n",
    "\n",
    "\n",
    "def move_and_check(position, action):\n",
    "    \"\"\"\n",
    "    Make a non-special move and check wheter\n",
    "    we're out of bounds.\n",
    "    If we're out of bounds, return the initial position\n",
    "    \"\"\"\n",
    "    new_position = position + action_map[action]\n",
    "    new_state = get_state(new_position)\n",
    "            \n",
    "    if is_out_of_bounds(new_position):\n",
    "        return position\n",
    "    else:\n",
    "        return new_position\n",
    "\n",
    "\n",
    "def move(state, action):\n",
    "    # move to special state\n",
    "    if state in special_map:\n",
    "        new_state = special_state_map[state]\n",
    "        new_position = get_pos(new_state)\n",
    "    # make a move\n",
    "    else:\n",
    "        position = get_pos(state)\n",
    "        new_position = move_and_check(position, action)\n",
    "        \n",
    "    return new_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9dffe-fb15-4eda-a757-ce5dba3e702b",
   "metadata": {},
   "source": [
    "## Constructing $p(s', r | a , s)$\n",
    "First build $p(s', r, s, a)$, then condition over $p(s,a) = \\sum_{s',r}p(s',r, a, s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae26785-2cbb-446b-a50c-28d4cc093dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4, 25, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing p(s',r | a, s)\n",
    "p_gridworld = np.zeros((state_size, n_rewards, state_size, n_actions))\n",
    "\n",
    "for state in range(state_size):\n",
    "    for action in action_map:\n",
    "\n",
    "        # obtain s' — new state\n",
    "        new_pos = move(state, action)\n",
    "        new_state = get_state(new_pos)\n",
    "        \n",
    "        # obtain r — reward\n",
    "        if state in special_states:\n",
    "            r = special_map[state]\n",
    "        elif state == new_state:\n",
    "            r = -1\n",
    "        else:\n",
    "            r = 0\n",
    "        \n",
    "        # r = r\n",
    "        a_pos = actions_ix_map[action]\n",
    "        r_pos = reward_map[r]\n",
    "        p_gridworld[new_state, r_pos, state, a_pos] = 1\n",
    "\n",
    "p_gridworld = p_gridworld / p_gridworld.sum(axis=(0,1), keepdims=True)\n",
    "p_gridworld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acde8e5e-4b01-404a-ab1e-5dfae34aebbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Σ_{s', r, a} r * p(s', r | a, s)\n",
    "b = einops.einsum(p_gridworld, rewards, \"s_prime r s a, r -> s\") / 4\n",
    "\n",
    "γ = 0.9\n",
    "I = np.eye(state_size)\n",
    "A = I - γ / 4 * einops.reduce(p_gridworld, \"s_prime r s a -> s s_prime\", \"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f76c3-b486-4a9c-ab26-3f033ad56383",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d383bf63-7cbb-467f-8d09-a696dec22a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3,  8.8,  4.4,  5.3,  1.5],\n",
       "       [ 1.5,  3. ,  2.3,  1.9,  0.5],\n",
       "       [ 0.1,  0.7,  0.7,  0.4, -0.4],\n",
       "       [-1. , -0.4, -0.4, -0.6, -1.2],\n",
       "       [-1.9, -1.3, -1.2, -1.4, -2. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(A, b).reshape(5, 5).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9528c-c15f-4cf3-8c51-a313d88b1e58",
   "metadata": {},
   "source": [
    "## Optimal state-value function\n",
    "**Bellman optimality equation**\n",
    "\n",
    "$$\n",
    "    v_{*}(s) = \\max_{a\\in\\mathcal{A}} \\sum_{s',r}p\\left( s', r \\vert s, a \\right)\\left[r + \\gamma v_*(s')\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c7ce85-1fb6-4ba0-aa34-185723b52a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bellman_optimality(vs):\n",
    "    rhs = (rewards[None, :] + γ * vs[:, None])\n",
    "    rhs = einops.einsum(rhs, p_gridworld, \"s_prime r, s_prime r s a -> s a\")\n",
    "    rhs = einops.reduce(rhs, \"s a -> s\", \"max\")\n",
    "    \n",
    "    return vs - rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcfbab19-e84e-4616-ab6c-c5e3f26022d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22. , 24.4, 22. , 19.4, 17.5],\n",
       "       [19.8, 22. , 19.8, 17.8, 16. ],\n",
       "       [17.8, 19.8, 17.8, 16. , 14.4],\n",
       "       [16. , 17.8, 16. , 14.4, 13. ],\n",
       "       [14.4, 16. , 14.4, 13. , 11.7]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = np.ones(25) # intial estimate of the optimal value function\n",
    "vs_star = optimize.broyden1(bellman_optimality, vs)\n",
    "vs_star.reshape(5, 5).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635863d-8886-401e-864e-79ea7afca4f3",
   "metadata": {},
   "source": [
    "### Optimal actions\n",
    "Having computed $v_*(s)$ for all $s\\in{\\cal S}$, we compute\n",
    "$$\n",
    "    v_{*,a}(s) := \\sum_{s',r}p(s',r | s, a)[r + \\gamma v_*(s')]\\ \\forall a\\in{\\cal A}\n",
    "$$\n",
    "and keep, for a given state $s$, all $a$ such that\n",
    "$$\n",
    "    v_*(s) = v_{*,a}(s).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b40b6a-7a0f-4c7f-950b-ad8cf9f76efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute expected returns for all actions at a given state\n",
    "action_expected_return = rewards[None, :] + γ * vs_star[:, None]\n",
    "action_expected_return = einops.einsum(action_expected_return, p_gridworld, \"s_prime r, s_prime r s a -> a s\")\n",
    "# check which actions obtain the optimal value-function\n",
    "optimal_actions = (action_expected_return == action_expected_return.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a304f056-930b-4610-b232-1af4c9d5d8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['r   ', 'urdl', 'l   ', 'urdl', 'l   '],\n",
       "       ['u   ', 'u   ', 'l   ', 'l   ', 'l   '],\n",
       "       ['r   ', 'u   ', 'u   ', 'u   ', 'l   '],\n",
       "       ['r   ', 'u   ', 'u   ', 'l   ', 'u   '],\n",
       "       ['r   ', 'u   ', 'u   ', 'l   ', 'l   ']], dtype='<U4')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Up, right, left, down actions\n",
    "actions_str = np.where(optimal_actions, np.array([\"u\",\"r\",\"d\",\"l\"])[:, None], \"\").T\n",
    "np.array([f'{\"\".join(row):4}' for row in actions_str]).reshape(5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
